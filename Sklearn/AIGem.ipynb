{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "['avia' 'it']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Gem_prof_ext.csv\")\n",
    "#X = music_data.drop(columns=[\"results\"]).astype('str')\n",
    "#music_data.convert_dtypes(convert_floating=True)\n",
    "X = data.drop(columns=[\"result\"])\n",
    "y = data[\"result\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "#clr = DecisionTreeClassifier()\n",
    "#clr = LogisticRegression()\n",
    "#clr = LinearSVC()\n",
    "#clr = GaussianNB()\n",
    "clr.fit(X_train, y_train)\n",
    "result = clr.score(X, y)\n",
    "#predictions = clr.predict([ [1,0,1,1,0,0,1,0,0,1], [0,1,0,1,0,1,0,0,1,0] ])\n",
    "predictions = clr.predict([[1.124], [1.653] ])\n",
    "print(result)\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'Gem_model_F.sav'\n",
    "pickle.dump(clr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gem_model_extF.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Gem_model_extF.sav'\n",
    "joblib.dump(clr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['science' 'people']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loaded_model1 = joblib.load(filename)\n",
    "print(loaded_model1.predict([[1.034], [1.972] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "#cristall = [0,1,0,1,0,1,0,0,1,0]\n",
    "#cristall = [1,1,1,1,0,1,1,0,0,1]\n",
    "#a = [1,1,1,1,0,1,1,0,0,1]\n",
    "gemlist = []\n",
    "final_list = []\n",
    "def gem_start(cristall):\n",
    "    i = 0\n",
    "    prediction = \"booba\"\n",
    "    gemlist = []\n",
    "    while i < 7:\n",
    "        \n",
    "        prediction_new = loaded_model.predict([cristall])\n",
    "        gemlist.insert(0, prediction_new[0])\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    result = [item for item, count in collections.Counter(gemlist).items() if count > 3]\n",
    "    rere = result[0]\n",
    "    #print(result[0])\n",
    "    final_list.append(rere)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0 \n",
    "final_list = []\n",
    "#b = [1,1,1,1,1,1,1,1,1,1]\n",
    "b = [1,1,1,1,0,0,0,0,0,0]\n",
    "a = b\n",
    "while j<9:\n",
    "    amount = a.count(1)\n",
    "    if amount >=3:\n",
    "        gem_start(a)\n",
    "    rere = result[0]\n",
    "    if a[j] == 1:\n",
    "        a = a[:j]+[0]+a[j+1:]\n",
    "    \n",
    "    #konec = [item for item, count in collections.Counter(final_list).items() if count > 3]\n",
    "    #print(a)\n",
    "    j +=1\n",
    "print(final_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_type is not a tensor type but '<class 'onnxconverter_common.data_types.FloatType'>'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskl2onnx\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_sklearn\n\u001b[0;32m      4\u001b[0m initial_type \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mfloat_input\u001b[39m\u001b[39m'\u001b[39m, FloatType([\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m]))]\n\u001b[1;32m----> 5\u001b[0m onx \u001b[39m=\u001b[39m convert_sklearn(loaded_model, initial_types\u001b[39m=\u001b[39;49minitial_type)\n\u001b[0;32m      6\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGem_model_extO.onnx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     f\u001b[39m.\u001b[39mwrite(onx\u001b[39m.\u001b[39mSerializeToString())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\convert.py:174\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[1;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[convert_sklearn] parse_sklearn_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 174\u001b[0m topology \u001b[39m=\u001b[39m parse_sklearn_model(\n\u001b[0;32m    175\u001b[0m     model, initial_types, target_opset, custom_conversion_functions,\n\u001b[0;32m    176\u001b[0m     custom_shape_calculators, custom_parsers, options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    177\u001b[0m     white_op\u001b[39m=\u001b[39;49mwhite_op, black_op\u001b[39m=\u001b[39;49mblack_op,\n\u001b[0;32m    178\u001b[0m     final_types\u001b[39m=\u001b[39;49mfinal_types, naming\u001b[39m=\u001b[39;49mnaming)\n\u001b[0;32m    180\u001b[0m \u001b[39m# Convert our Topology object into ONNX. The outcome is an ONNX model.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m options \u001b[39m=\u001b[39m _process_options(model, options)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\_parse.py:787\u001b[0m, in \u001b[0;36mparse_sklearn_model\u001b[1;34m(model, initial_types, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, white_op, black_op, final_types, naming)\u001b[0m\n\u001b[0;32m    784\u001b[0m     raw_model_container\u001b[39m.\u001b[39madd_input(variable)\n\u001b[0;32m    786\u001b[0m \u001b[39m# Parse the input scikit-learn model as a Topology object.\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m outputs \u001b[39m=\u001b[39m parse_sklearn(scope, model, inputs,\n\u001b[0;32m    788\u001b[0m                         custom_parsers\u001b[39m=\u001b[39;49mcustom_parsers,\n\u001b[0;32m    789\u001b[0m                         final_types\u001b[39m=\u001b[39;49mfinal_types)\n\u001b[0;32m    791\u001b[0m \u001b[39m# The object raw_model_container is a part of the topology we're\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[39m# going to return. We use it to store the outputs of the\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[39m# scikit-learn's computational graph.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m final_types \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(final_types) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(outputs):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\_parse.py:707\u001b[0m, in \u001b[0;36mparse_sklearn\u001b[1;34m(scope, model, inputs, custom_parsers, final_types)\u001b[0m\n\u001b[0;32m    704\u001b[0m             o\u001b[39m.\u001b[39mtype \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mtype\n\u001b[0;32m    705\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m--> 707\u001b[0m res \u001b[39m=\u001b[39m _parse_sklearn(\n\u001b[0;32m    708\u001b[0m     scope, model, inputs, custom_parsers\u001b[39m=\u001b[39;49mcustom_parsers)\n\u001b[0;32m    709\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m res:\n\u001b[0;32m    710\u001b[0m     r\u001b[39m.\u001b[39minit_status(is_leaf\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\_parse.py:644\u001b[0m, in \u001b[0;36m_parse_sklearn\u001b[1;34m(scope, model, inputs, custom_parsers, alias)\u001b[0m\n\u001b[0;32m    641\u001b[0m     outputs \u001b[39m=\u001b[39m custom_parsers[tmodel](scope, model, inputs,\n\u001b[0;32m    642\u001b[0m                                      custom_parsers\u001b[39m=\u001b[39mcustom_parsers)\n\u001b[0;32m    643\u001b[0m \u001b[39melif\u001b[39;00m tmodel \u001b[39min\u001b[39;00m sklearn_parsers_map:\n\u001b[1;32m--> 644\u001b[0m     outputs \u001b[39m=\u001b[39m sklearn_parsers_map[tmodel](scope, model, inputs,\n\u001b[0;32m    645\u001b[0m                                           custom_parsers\u001b[39m=\u001b[39;49mcustom_parsers)\n\u001b[0;32m    646\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pipeline\u001b[39m.\u001b[39mPipeline):\n\u001b[0;32m    647\u001b[0m     parser \u001b[39m=\u001b[39m sklearn_parsers_map[pipeline\u001b[39m.\u001b[39mPipeline]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\_parse.py:489\u001b[0m, in \u001b[0;36m_parse_sklearn_classifier\u001b[1;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[0;32m    485\u001b[0m options \u001b[39m=\u001b[39m scope\u001b[39m.\u001b[39mget_options(model, \u001b[39mdict\u001b[39m(zipmap\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m    486\u001b[0m no_zipmap \u001b[39m=\u001b[39m (\n\u001b[0;32m    487\u001b[0m     (\u001b[39misinstance\u001b[39m(options[\u001b[39m'\u001b[39m\u001b[39mzipmap\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m options[\u001b[39m'\u001b[39m\u001b[39mzipmap\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     (model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39min\u001b[39;00m [NuSVC, SVC] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39mprobability))\n\u001b[1;32m--> 489\u001b[0m probability_tensor \u001b[39m=\u001b[39m _parse_sklearn_simple_model(\n\u001b[0;32m    490\u001b[0m     scope, model, inputs, custom_parsers\u001b[39m=\u001b[39;49mcustom_parsers)\n\u001b[0;32m    492\u001b[0m \u001b[39mif\u001b[39;00m no_zipmap:\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39moutput_class_labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\_parse.py:161\u001b[0m, in \u001b[0;36m_parse_sklearn_simple_model\u001b[1;34m(scope, model, inputs, custom_parsers, alias)\u001b[0m\n\u001b[0;32m    159\u001b[0m     prob_dtype \u001b[39m=\u001b[39m FloatTensorType()\n\u001b[0;32m    160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     prob_dtype \u001b[39m=\u001b[39m guess_tensor_type(inputs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtype)\n\u001b[0;32m    162\u001b[0m probability_tensor_variable \u001b[39m=\u001b[39m scope\u001b[39m.\u001b[39mdeclare_local_variable(\n\u001b[0;32m    163\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mprobabilities\u001b[39m\u001b[39m'\u001b[39m, prob_dtype)\n\u001b[0;32m    164\u001b[0m this_operator\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mappend(label_variable)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skl2onnx\\common\\data_types.py:400\u001b[0m, in \u001b[0;36mguess_tensor_type\u001b[1;34m(data_type)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[39mreturn\u001b[39;00m data_type\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m()\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_type, (\n\u001b[0;32m    397\u001b[0m         Int64TensorType, Int32TensorType, BooleanTensorType,\n\u001b[0;32m    398\u001b[0m         FloatTensorType, StringTensorType, DoubleTensorType,\n\u001b[0;32m    399\u001b[0m         Int8TensorType, UInt8TensorType)):\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata_type is not a tensor type but \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    402\u001b[0m             \u001b[39mtype\u001b[39m(data_type)))\n\u001b[0;32m    403\u001b[0m \u001b[39mreturn\u001b[39;00m FloatTensorType()\n",
      "\u001b[1;31mTypeError\u001b[0m: data_type is not a tensor type but '<class 'onnxconverter_common.data_types.FloatType'>'."
     ]
    }
   ],
   "source": [
    "\n",
    "from skl2onnx.common.data_types import FloatType\n",
    "from skl2onnx import convert_sklearn\n",
    "\n",
    "initial_type = [('float_input', FloatType([None, 1]))]\n",
    "onx = convert_sklearn(loaded_model, initial_types=initial_type)\n",
    "with open(\"Gem_model_extO.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meteorolog' 'programist' 'politic' 'logist' 'vedushi' 'teacher'\n",
      " 'economy' 'engeneer' 'pilot' 'analitic' 'antropolog' 'buhgalter'\n",
      " 'nanoengeneer' 'kosmetolog' 'radiobiolog']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import onnxruntime as rt\n",
    "sess = rt.InferenceSession(\"Gem2.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onnx = sess.run(None, {input_name: X_train.values.astype(np.float32)})[0]\n",
    "print(pred_onnx)\n",
    "print(sess.predict([[1.034], [1.972]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science science programist pilot pilot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "def remove_duplicate(s): \n",
    "    return \"\".join(OrderedDict.fromkeys(s))\n",
    "    \n",
    "data = \"1.045 1.046 1.056 1.456 1.456\"\n",
    "data = data.split(' ')\n",
    "final_res_str = \"\"\n",
    "i=0\n",
    "while i < len(data):\n",
    "    pred = loaded_model.predict([[float(data[i])]])\n",
    "    if i == 0:\n",
    "        final_res_str = final_res_str + str(pred[0])\n",
    "    else:\n",
    "        final_res_str = final_res_str + \" \" + str(pred[0])\n",
    "    \n",
    "    i = i + 1\n",
    "#final_res_str = remove_duplicate(final_res_str)\n",
    "print(final_res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['engeneer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.predict([[1.045]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
